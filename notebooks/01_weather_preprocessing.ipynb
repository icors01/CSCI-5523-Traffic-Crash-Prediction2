{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "808b3303",
   "metadata": {},
   "source": [
    "Data from: https://www.ncei.noaa.gov/cdo-web/search?datasetid=GHCND\n",
    "\n",
    "Collected Daily Summaries from 3 different stations to find average weather across regions of Minnesota: \n",
    "- INTERNATIONAL FALLS INTERNATIONAL AIRPORT, MN US (N Region)\n",
    "- MINNEAPOLIS ST. PAUL INTERNATIONAL AIRPORT, MN US (SE Region)\n",
    "- ROCHESTER INTERNATIONAL AIRPORT, MN US (S/SE Region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253e43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa6f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TOBS</th>\n",
       "      <th>WT01</th>\n",
       "      <th>WT02</th>\n",
       "      <th>WT03</th>\n",
       "      <th>WT04</th>\n",
       "      <th>WT05</th>\n",
       "      <th>WT06</th>\n",
       "      <th>WT08</th>\n",
       "      <th>WT09</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10682</th>\n",
       "      <td>USW00014922</td>\n",
       "      <td>MINNEAPOLIS ST. PAUL INTERNATIONAL AIRPORT, MN US</td>\n",
       "      <td>9/30/2025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           STATION                                               NAME       DATE  PRCP  SNOW  SNWD  TAVG  TMAX  TMIN  TOBS  WT01  WT02  WT03  WT04  WT05  WT06  WT08  WT09\n",
       "10682  USW00014922  MINNEAPOLIS ST. PAUL INTERNATIONAL AIRPORT, MN US  9/30/2025   0.0   0.0   0.0   NaN  84.0  66.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/weather_data.csv')\n",
    "df.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23874cf",
   "metadata": {},
   "source": [
    "Weather Type Codes\n",
    "- WT01\tFog, ice fog, or freezing fog (or haze): Reduced visibility, increased slickness.\n",
    "- WT02\tHeavy fog or thick fog: Severely reduced visibility (major crash factor).\n",
    "- WT03\tThunder: Often correlated with heavy rain and sudden visibility changes.\n",
    "- WT04\tIce pellets, sleet, snow pellets, or small hail: Immediate increase in road slickness and difficulty controlling vehicles.\n",
    "- WT05\tHail (larger): Can cause property damage and sudden driver maneuvers.\n",
    "- WT06\tGlaze or rime (freezing rain): The most dangerous condition for black ice formation.\n",
    "- WT08\tSmoke or ash: Reduced air quality and significant visibility reduction.\n",
    "- WT09\tBlowing or drifting snow: Reduced visibility and accumulation creating slick, uneven conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56028768",
   "metadata": {},
   "source": [
    "## 1. Initial Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8e8354e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial NaN values in TAVG: 134, NaN values in PRCP: 5, NaN values in SNOW: 9\n"
     ]
    }
   ],
   "source": [
    "df['DATE'] = pd.to_datetime(df['DATE'], format='%m/%d/%Y')\n",
    "df = df.sort_values(by='DATE', ascending=True)\n",
    "\n",
    "# Checking NaN values in WT columns - filling NaN with 0\n",
    "wt_cols = ['WT01', 'WT02', 'WT03', 'WT04', 'WT05', 'WT06', 'WT08', 'WT09']\n",
    "df[wt_cols] = df[wt_cols].fillna(0)\n",
    "\n",
    "# Count NaN in TAVG column\n",
    "cols_to_check = ['TAVG', 'TMAX', 'TMIN', 'PRCP', 'SNOW']\n",
    "for col in cols_to_check: \n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Initial NaN counts\n",
    "print(f'Initial NaN values in TAVG: {df[\"TAVG\"].isna().sum()}, NaN values in PRCP: {df[\"PRCP\"].isna().sum()}, NaN values in SNOW: {df[\"SNOW\"].isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17db45a4",
   "metadata": {},
   "source": [
    "## 2. Dealing with NaNs for Numerical Features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2454083f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs remaining in TAVG after TMAX/TMIN imputation: 30\n",
      "NaNs remaining in TAVG after peer median fill: 0\n",
      "NaNs remaining in PRCP after peer median fill: 0\n",
      "NaNs remaining in SNOW after peer median fill: 0\n"
     ]
    }
   ],
   "source": [
    "numerical_features = ['TAVG', 'PRCP', 'SNOW'] \n",
    "\n",
    "# First check if TMAX and TMIN are available to find TAVG\n",
    "df['TAVG_ESTIMATE'] = (df['TMAX'] + df['TMIN']) / 2\n",
    "df['TAVG'] = df['TAVG'].fillna(df['TAVG_ESTIMATE'])\n",
    "print(f\"NaNs remaining in TAVG after TMAX/TMIN imputation: {df['TAVG'].isnull().sum()}\")\n",
    "\n",
    "# If NaN still present, fill with daily median across stations\n",
    "for col in numerical_features:\n",
    "    daily_median_across_stations = df.groupby('DATE')[col].transform('median')\n",
    "    df[col] = df[col].fillna(daily_median_across_stations)\n",
    "    print(f\"NaNs remaining in {col} after peer median fill: {df[col].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aeb9ee",
   "metadata": {},
   "source": [
    "## 3. Aggregate and Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "976dbe2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           DATE  TAVG_MEDIAN  PRCP_MEDIAN  SNOW_MEDIAN  WT01_MAX  WT02_MAX  WT03_MAX  WT04_MAX  WT05_MAX  WT06_MAX  WT08_MAX  WT09_MAX\n",
      "164  2016-06-13         68.0         0.03          0.0       1.0       1.0       1.0       0.0       0.0       1.0       0.0       0.0\n",
      "176  2016-06-25         76.0         0.37          0.0       1.0       1.0       1.0       0.0       0.0       0.0       1.0       0.0\n",
      "2690 2023-05-14         57.0         0.48          0.0       1.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "2471 2022-10-07         42.0         0.00          0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "2929 2024-01-08         24.0         0.01          0.2       1.0       0.0       0.0       0.0       0.0       1.0       0.0       0.0\n",
      "3140 2024-08-06         64.0         0.00          0.0       1.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "1665 2020-07-23         64.0         0.00          0.0       1.0       1.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "2913 2023-12-23         42.0         0.00          0.0       1.0       1.0       0.0       0.0       0.0       1.0       0.0       0.0\n",
      "445  2017-03-21         36.0         0.00          0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "1810 2020-12-15         15.0         0.00          0.0       1.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3561 entries, 0 to 3560\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   DATE         3561 non-null   datetime64[ns]\n",
      " 1   TAVG_MEDIAN  3561 non-null   float64       \n",
      " 2   PRCP_MEDIAN  3561 non-null   float64       \n",
      " 3   SNOW_MEDIAN  3561 non-null   float64       \n",
      " 4   WT01_MAX     3561 non-null   float64       \n",
      " 5   WT02_MAX     3561 non-null   float64       \n",
      " 6   WT03_MAX     3561 non-null   float64       \n",
      " 7   WT04_MAX     3561 non-null   float64       \n",
      " 8   WT05_MAX     3561 non-null   float64       \n",
      " 9   WT06_MAX     3561 non-null   float64       \n",
      " 10  WT08_MAX     3561 non-null   float64       \n",
      " 11  WT09_MAX     3561 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(11)\n",
      "memory usage: 334.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "daily_median_weather = df.groupby('DATE')[numerical_features].median().reset_index()\n",
    "daily_median_weather.columns = ['DATE'] + [f'{col}_MEDIAN' for col in numerical_features]\n",
    "\n",
    "daily_max_wt = df.groupby('DATE')[wt_cols].max().reset_index()\n",
    "daily_max_wt.columns = ['DATE'] + [f'{col}_MAX' for col in wt_cols]\n",
    "\n",
    "final_weather_df = pd.merge(daily_median_weather, daily_max_wt, on='DATE', how='inner') \n",
    "print(final_weather_df.sample(10))\n",
    "print(final_weather_df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0120a8ce",
   "metadata": {},
   "source": [
    "## 4. Output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1047d2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved to: ../data/processed\\cleaned_weather.csv\n"
     ]
    }
   ],
   "source": [
    "# Create processed data directory if it doesn't exist\n",
    "import os\n",
    "processed_dir = '../data/processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "cleaned_file_path = os.path.join(processed_dir, 'cleaned_weather.csv')\n",
    "final_weather_df.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved to: {cleaned_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
